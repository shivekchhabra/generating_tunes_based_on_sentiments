{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e21bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn as sk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import accuracy_score\n",
    "import featuretools as ft\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from emotion_classification_model import EmotionClassifier, feature_names\n",
    "import pandas as pd\n",
    "\n",
    "import sys,os\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "def accuracy_metrics(y_test, y_pred):\n",
    "    happy_classified = 0\n",
    "    sad_classified = 0\n",
    "    thriller_classified = 0\n",
    "\n",
    "    happy_total_count = 0\n",
    "    sad_total_count = 0\n",
    "    thriller_total_count = 0\n",
    "\n",
    "    y_test_list = list(y_test)\n",
    "    for i in range(len(y_test_list)):\n",
    "        if y_test_list[i] == 0:\n",
    "            happy_total_count += 1\n",
    "        if y_test_list[i] == 1:\n",
    "            sad_total_count += 1\n",
    "        if y_test_list[i] == 2:\n",
    "            thriller_total_count += 1\n",
    "\n",
    "        if y_test_list[i] == 0 and y_pred[i] == 0:\n",
    "            happy_classified += 1\n",
    "        if y_test_list[i] == 1 and y_pred[i] == 1:\n",
    "            sad_classified += 1\n",
    "        if y_test_list[i] == 2 and y_pred[i] == 2:\n",
    "            thriller_classified += 1\n",
    "            \n",
    "    happy_accuracy = happy_classified/happy_total_count\n",
    "    sad_accuracy = sad_classified/sad_total_count\n",
    "    thriller_accuracy = thriller_classified/thriller_total_count\n",
    "    \n",
    "    return happy_accuracy, sad_accuracy, thriller_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de5b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all midi to wav files\n",
    "\n",
    "def midi_to_wav(path):\n",
    "    files=os.listdir(path)\n",
    "    for f in files:\n",
    "        if(f.split('.')[-1]=='mid' or f.split('.')[-1]=='midi'):\n",
    "            FluidSynth().midi_to_audio(path + \"/\" + f, path + \"/\" + f+'-output.wav')\n",
    "\n",
    "# midi_to_wav(\"/Users/gokul/Downloads/MTD/predict_tunes/thriller\")\n",
    "# midi_to_wav(\"/Users/gokul/Downloads/MTD/predict_tunes/happy\")\n",
    "# midi_to_wav(\"/Users/gokul/Downloads/MTD/predict_tunes/sad\")\n",
    "\n",
    "# midi_to_wav(\"/Users/gokul/Downloads/MTD/predict_tunes/happyzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d17ec1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation accuracy 0.9868421052631579\n",
      "\n",
      "Happy validation accuracy 0.9565217391304348\n",
      "Sad validation accuracy 1.0\n",
      "Thriller validation accuracy 1.0\n",
      "\n",
      "Happy train accuracy 0.9848484848484849\n",
      "Sad train accuracy 1.0\n",
      "Thriller train accuracy 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/initial_collection_model.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model for initial collection without the anger dataset\n",
    "# Random test/train split\n",
    "\n",
    "ec = EmotionClassifier()\n",
    "happyzipdf = pd.DataFrame(columns=list(feature_names))\n",
    "initial_collection_features = pd.read_pickle(\"../artefacts\" +\"/\"+ 'features.csv')\n",
    "\n",
    "train = initial_collection_features\n",
    "train['indexcol'] = range(1, train.shape[0] + 1)\n",
    "train = train[train[\"label\"] != \"anger\"]\n",
    "le = LabelEncoder()\n",
    "train[\"label_encoded\"] = le.fit_transform(train[\"label\"])\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "# print(le_name_mapping)\n",
    "label = train[\"label_encoded\"]\n",
    "train = train.drop(columns=[\"label\", \"label_encoded\"])\n",
    "def featurize(entry):\n",
    "    return tuple(entry)\n",
    "train[\"featurize\"] = train.apply(featurize, axis=1)\n",
    "\n",
    "result_model = \"\"\n",
    "threshold_accuracy = 0.0\n",
    "for i in range(25):\n",
    "    x_train, x_test, y_train, y_test = sk.model_selection.train_test_split(train, label, test_size=0.3)\n",
    "\n",
    "#     print(x_train.shape[0], x_train.shape[1])\n",
    "#     print(x_test.shape[0], x_test.shape[1])\n",
    "#     print(y_train.shape[0])\n",
    "#     print(y_test.shape[0])\n",
    "\n",
    "    train_list = list(x_train[\"featurize\"])\n",
    "    initial_collection_model = RandomForestClassifier().fit(train_list, y_train)\n",
    "    y_pred = initial_collection_model.predict(list(x_test[\"featurize\"]))\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    if score > threshold_accuracy:\n",
    "        result_model = initial_collection_model\n",
    "        threshold_accuracy = score\n",
    "        happy_accuracy, sad_accuracy, thriller_accuracy = accuracy_metrics(y_test, y_pred)\n",
    "        \n",
    "print(\"Overall validation accuracy\", threshold_accuracy)\n",
    "print()\n",
    "print(\"Happy validation accuracy\", happy_accuracy)\n",
    "print(\"Sad validation accuracy\",  sad_accuracy)\n",
    "print(\"Thriller validation accuracy\", thriller_accuracy)\n",
    "\n",
    "x_pred = result_model.predict(list(x_train[\"featurize\"]))\n",
    "happy_accuracy, sad_accuracy, thriller_accuracy = accuracy_metrics(list(y_train), x_pred)\n",
    "print()\n",
    "print(\"Happy train accuracy\", happy_accuracy)\n",
    "print(\"Sad train accuracy\",  sad_accuracy)\n",
    "print(\"Thriller train accuracy\", thriller_accuracy)\n",
    "\n",
    "dump(result_model, \"../models\" + \"/\" + 'initial_collection_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea5f14ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation accuracy 0.9117647058823529\n",
      "\n",
      "Happy validation accuracy 0.9444444444444444\n",
      "Sad validation accuracy 1.0\n",
      "Thriller validation accuracy 0.375\n",
      "\n",
      "Happy train accuracy 0.9791666666666666\n",
      "Sad train accuracy 1.0\n",
      "Thriller train accuracy 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/final_midi_model.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model for final midi collection without the anger/Various dataset\n",
    "# Random test/train split\n",
    "\n",
    "ec = EmotionClassifier()\n",
    "happyzipdf = pd.DataFrame(columns=list(feature_names))\n",
    "final_midi_features = pd.read_pickle(\"../artefacts\" +\"/\"+ 'predict_features_mid.csv')\n",
    "\n",
    "train = final_midi_features\n",
    "train['indexcol'] = range(1, train.shape[0] + 1)\n",
    "train = train[train[\"label\"] != \"anger\"]\n",
    "le = LabelEncoder()\n",
    "train[\"label_encoded\"] = le.fit_transform(train[\"label\"])\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "# print(le_name_mapping)\n",
    "label = train[\"label_encoded\"]\n",
    "train = train.drop(columns=[\"label\", \"label_encoded\"])\n",
    "def featurize(entry):\n",
    "    return tuple(entry)\n",
    "train[\"featurize\"] = train.apply(featurize, axis=1)\n",
    "\n",
    "result_model = \"\"\n",
    "threshold_accuracy = 0.0\n",
    "for i in range(25):\n",
    "    x_train, x_test, y_train, y_test = sk.model_selection.train_test_split(train, label, test_size=0.3)\n",
    "\n",
    "#     print(x_train.shape[0], x_train.shape[1])\n",
    "#     print(x_test.shape[0], x_test.shape[1])\n",
    "#     print(y_train.shape[0])\n",
    "#     print(y_test.shape[0])\n",
    "\n",
    "    train_list = list(x_train[\"featurize\"])\n",
    "    final_midi_model = RandomForestClassifier().fit(train_list, y_train)\n",
    "    y_pred = final_midi_model.predict(list(x_test[\"featurize\"]))\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    if score > threshold_accuracy:\n",
    "        result_model = final_midi_model\n",
    "        threshold_accuracy = score\n",
    "        \n",
    "        happy_accuracy, sad_accuracy, thriller_accuracy = accuracy_metrics(y_test, y_pred)\n",
    "        \n",
    "print(\"Overall validation accuracy\", threshold_accuracy)\n",
    "print()\n",
    "print(\"Happy validation accuracy\", happy_accuracy)\n",
    "print(\"Sad validation accuracy\",  sad_accuracy)\n",
    "print(\"Thriller validation accuracy\", thriller_accuracy)\n",
    "\n",
    "x_pred = result_model.predict(list(x_train[\"featurize\"]))\n",
    "happy_accuracy, sad_accuracy, thriller_accuracy = accuracy_metrics(list(y_train), x_pred)\n",
    "print()\n",
    "print(\"Happy train accuracy\", happy_accuracy)\n",
    "print(\"Sad train accuracy\",  sad_accuracy)\n",
    "print(\"Thriller train accuracy\", thriller_accuracy)\n",
    "\n",
    "\n",
    "dump(result_model, \"../models\" + \"/\" + 'final_midi_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a26c2a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation accuracy 0.9629629629629629\n",
      "\n",
      "Happy accuracy 1.0\n",
      "Sad accuracy 0.8888888888888888\n",
      "Thriller accuracy 1.0\n",
      "\n",
      "Happy train accuracy 1.0\n",
      "Sad train accuracy 0.9523809523809523\n",
      "Thriller train accuracy 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/final_midi_303030_model.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model for final midi collection without the anger/Various dataset\n",
    "# Random test/train split 30/30/30\n",
    "\n",
    "ec = EmotionClassifier()\n",
    "happyzipdf = pd.DataFrame(columns=list(feature_names))\n",
    "final_midi_303030_features = pd.read_pickle(\"../artefacts\" +\"/\"+'predict_features_mid.csv')\n",
    "\n",
    "df_unskew = final_midi_303030_features\n",
    "df_unskew = df_unskew[df_unskew[\"label\"] != \"anger\"]\n",
    "df1 = (df_unskew[df_unskew['label'] == 'sad']).sample(frac=.24)\n",
    "df2 = (df_unskew[df_unskew['label'] == 'happy']).sample(frac=.44)\n",
    "df3 = df_unskew[df_unskew['label'] == 'thriller']\n",
    "frames = [df1, df2, df3]\n",
    "result = pd.concat(frames)\n",
    "\n",
    "train = result\n",
    "train['indexcol'] = range(1, train.shape[0] + 1)\n",
    "train = train[train[\"label\"] != \"anger\"]\n",
    "le = LabelEncoder()\n",
    "train[\"label_encoded\"] = le.fit_transform(train[\"label\"])\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "# print(le_name_mapping)\n",
    "label = train[\"label_encoded\"]\n",
    "train = train.drop(columns=[\"label\", \"label_encoded\"])\n",
    "def featurize(entry):\n",
    "    return tuple(entry)\n",
    "train[\"featurize\"] = train.apply(featurize, axis=1)\n",
    "\n",
    "result_model = \"\"\n",
    "threshold_accuracy = 0.0\n",
    "for i in range(25):\n",
    "    x_train, x_test, y_train, y_test = sk.model_selection.train_test_split(train, label, test_size=0.3)\n",
    "#     print(x_train.shape[0], x_train.shape[1])\n",
    "#     print(x_test.shape[0], x_test.shape[1])\n",
    "#     print(y_train.shape[0])\n",
    "#     print(y_test.shape[0])\n",
    "    train_list = list(x_train[\"featurize\"])\n",
    "    final_midi_303030_model = RandomForestClassifier().fit(train_list, y_train)\n",
    "    y_pred = final_midi_303030_model.predict(list(x_test[\"featurize\"]))\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    if score > threshold_accuracy:\n",
    "        result_model = final_midi_303030_model\n",
    "        threshold_accuracy = score\n",
    "        \n",
    "        happy_accuracy, sad_accuracy, thriller_accuracy = accuracy_metrics(y_test, y_pred)\n",
    "        \n",
    "print(\"Overall validation accuracy\", threshold_accuracy)\n",
    "print()\n",
    "print(\"Happy accuracy\", happy_accuracy)\n",
    "print(\"Sad accuracy\",  sad_accuracy)\n",
    "print(\"Thriller accuracy\", thriller_accuracy)\n",
    "\n",
    "x_pred = result_model.predict(list(x_train[\"featurize\"]))\n",
    "happy_accuracy, sad_accuracy, thriller_accuracy = accuracy_metrics(list(y_train), x_pred)\n",
    "print()\n",
    "print(\"Happy train accuracy\", happy_accuracy)\n",
    "print(\"Sad train accuracy\",  sad_accuracy)\n",
    "print(\"Thriller train accuracy\", thriller_accuracy)\n",
    "\n",
    "dump(result_model, \"../models\" + \"/\" + 'final_midi_303030_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f46d57fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation accuracy 0.9629629629629629\n",
      "\n",
      "Happy validation accuracy 0.9230769230769231\n",
      "Sad validation accuracy 1.0\n",
      "Thriller validation accuracy 1.0\n",
      "\n",
      "Happy train accuracy 0.9583333333333334\n",
      "Sad train accuracy 1.0\n",
      "Thriller train accuracy 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/final_midi_random_equity_model.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model for final midi collection without the anger/Various dataset\n",
    "# Micro-managed test/train split -> Same percentage of songs in all genres for training and testing\n",
    "\n",
    "ec = EmotionClassifier()\n",
    "happyzipdf = pd.DataFrame(columns=list(feature_names))\n",
    "final_midi_random_equity_features = pd.read_pickle(\"../artefacts\" +\"/\"+'predict_features_mid.csv')\n",
    "\n",
    "df_unskew = final_midi_random_equity_features\n",
    "df_unskew = df_unskew[df_unskew[\"label\"] != \"anger\"]\n",
    "train_sad, test_sad = sk.model_selection.train_test_split((df_unskew[df_unskew['label'] == 'sad']), test_size=0.2)\n",
    "train_happy, test_happy = sk.model_selection.train_test_split((df_unskew[df_unskew['label'] == 'happy']), test_size=0.2)\n",
    "train_thriller, test_thriller = sk.model_selection.train_test_split((df_unskew[df_unskew['label'] == 'thriller']), test_size=0.2)\n",
    "\n",
    "frames = [train_sad, train_happy, train_thriller]\n",
    "train = pd.concat(frames)\n",
    "\n",
    "frames = [test_sad, test_happy, test_thriller]\n",
    "test = pd.concat(frames)\n",
    "\n",
    "train = result\n",
    "train['indexcol'] = range(1, train.shape[0] + 1)\n",
    "train = train[train[\"label\"] != \"anger\"]\n",
    "le = LabelEncoder()\n",
    "train[\"label_encoded\"] = le.fit_transform(train[\"label\"])\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "# print(le_name_mapping)\n",
    "label = train[\"label_encoded\"]\n",
    "train = train.drop(columns=[\"label\", \"label_encoded\"])\n",
    "def featurize(entry):\n",
    "    return tuple(entry)\n",
    "train[\"featurize\"] = train.apply(featurize, axis=1)\n",
    "\n",
    "result_model = \"\"\n",
    "threshold_accuracy = 0.0\n",
    "for i in range(25):\n",
    "    x_train, x_test, y_train, y_test = sk.model_selection.train_test_split(train, label, test_size=0.3)\n",
    "#     print(x_train.shape[0], x_train.shape[1])\n",
    "#     print(x_test.shape[0], x_test.shape[1])\n",
    "#     print(y_train.shape[0])\n",
    "#     print(y_test.shape[0])\n",
    "    train_list = list(x_train[\"featurize\"])\n",
    "    final_midi_random_equity_model = RandomForestClassifier().fit(train_list, y_train)\n",
    "    y_pred = final_midi_random_equity_model.predict(list(x_test[\"featurize\"]))\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    if score > threshold_accuracy:\n",
    "        result_model = final_midi_random_equity_model\n",
    "        threshold_accuracy = score\n",
    "        \n",
    "        happy_accuracy, sad_accuracy, thriller_accuracy = accuracy_metrics(y_test, y_pred)\n",
    "        \n",
    "print(\"Overall validation accuracy\", threshold_accuracy)\n",
    "print()\n",
    "print(\"Happy validation accuracy\", happy_accuracy)\n",
    "print(\"Sad validation accuracy\",  sad_accuracy)\n",
    "print(\"Thriller validation accuracy\", thriller_accuracy)\n",
    "\n",
    "\n",
    "x_pred = result_model.predict(list(x_train[\"featurize\"]))\n",
    "happy_accuracy, sad_accuracy, thriller_accuracy = accuracy_metrics(list(y_train), x_pred)\n",
    "print()\n",
    "print(\"Happy train accuracy\", happy_accuracy)\n",
    "print(\"Sad train accuracy\",  sad_accuracy)\n",
    "print(\"Thriller train accuracy\", thriller_accuracy)\n",
    "\n",
    "dump(result_model, \"../models\" + \"/\" + 'final_midi_random_equity_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4e100dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction happyzipdf generated songs\n",
    "\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn as sk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import accuracy_score\n",
    "import featuretools as ft\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from emotion_classification_model import EmotionClassifier, feature_names\n",
    "import pandas as pd\n",
    "\n",
    "import sys,os\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "ec = EmotionClassifier()\n",
    "\n",
    "# happyzipdf = pd.DataFrame(columns=list(feature_names))\n",
    "# happyzipdf = ec.add_features(happyzipdf, \"/Users/gokul/Downloads/MTD/predict_tunes/happyzip\", \"happy\", \".wav\")\n",
    "# happyzipdf.to_pickle('happyzipdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb0c5e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from emotion_classification_model import EmotionClassifier, feature_names\n",
    "# from joblib import dump, load\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import os\n",
    "# from mido import MidiFile\n",
    "# from pydub import AudioSegment\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# happyzipdf = pd.read_pickle(\"../artefacts\" +\"/\"+ 'happyzipdf.csv')\n",
    "# happyzipdf['indexcol'] = range(1, happyzipdf.shape[0] + 1)\n",
    "# le = LabelEncoder()\n",
    "# happyzipdf[\"label_encoded\"] = le.fit_transform(happyzipdf[\"label\"])\n",
    "# le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "# print(le_name_mapping)\n",
    "# label = happyzipdf[\"label_encoded\"]\n",
    "# happyzipdf = happyzipdf.drop(columns=[\"label\", \"label_encoded\"])\n",
    "# happyzipdf = happyzipdf.fillna(0)\n",
    "# happyzipdf[\"featurize\"] = happyzipdf.apply(ec.featurize, axis=1)\n",
    "\n",
    "# model = load(\"../models\" + \"/\" + \"'initial_collection_model.joblib'\")\n",
    "# y_pred = model.predict(list(happyzipdf[\"featurize\"]))\n",
    "# print(accuracy_score(label, y_pred))\n",
    "\n",
    "# model = load(\"../models\" + \"/\" + 'final_midi_model.joblib')\n",
    "# y_pred = model.predict(list(happyzipdf[\"featurize\"]))\n",
    "# print(accuracy_score(label, y_pred))\n",
    "\n",
    "# model = load(\"../models\" + \"/\" + 'final_midi_303030_model.joblib')\n",
    "# y_pred = model.predict(list(happyzipdf[\"featurize\"]))\n",
    "# print(accuracy_score(label, y_pred))\n",
    "\n",
    "# model = load(\"../models\" + \"/\" + 'final_midi_random_equity_model.joblib')\n",
    "# y_pred = model.predict(list(happyzipdf[\"featurize\"]))\n",
    "# print(accuracy_score(label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0509a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_wav(path):\n",
    "    files=os.listdir(path)\n",
    "    for f in files:\n",
    "        if(f.split('.')[-1]=='mid' or f.split('.')[-1]=='midi'):\n",
    "            FluidSynth().midi_to_audio(path + \"/\" + f, path + \"/\" + f+'-output.wav')\n",
    "\n",
    "midi_to_wav(\"/Users/gokul/Downloads/MTD/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b029608",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = EmotionClassifier()\n",
    "test_df = pd.DataFrame(columns=list(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad0887c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>...</th>\n",
       "      <th>at</th>\n",
       "      <th>au</th>\n",
       "      <th>av</th>\n",
       "      <th>aw</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>ba</th>\n",
       "      <th>bb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z, aa, ab, ac, ad, ae, af, ag, ah, ai, aj, ak, al, am, an, ao, ap, aq, ar, at, au, av, aw, ax, ay, az, ba, bb, label]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 54 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab647a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
